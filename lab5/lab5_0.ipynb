{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "lab5_0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "v0BtAX1--7l_"
      },
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "34f006aa7eb4bbc683c39b7059021da900180908",
        "id": "tUurNfvF-7mc"
      },
      "source": [
        "A tensor is a number, vector, matrix or any n-dimensional array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0b65b6bb4d15127b1d51f09abf616cfd29fa48b4",
        "id": "DAOgSWEp-7oF"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c1beecda01bc332596edd193cade30006e3f6cbf",
        "id": "-Fi1M6pd-7oJ"
      },
      "source": [
        "We'll create a model that predicts crop yeilds for apples (*target variable*) by looking at the average temperature, rainfall and humidity (*input variables or features*) in different regions. \n",
        "\n",
        "Here's the training data:\n",
        "\n",
        ">Temp | Rain | Humidity | Prediction\n",
        ">--- | --- | --- | ---\n",
        "> 73 | 67 | 43 | 56\n",
        "> 91 | 88 | 64 | 81\n",
        "> 87 | 134 | 58 | 119\n",
        "> 102 | 43 | 37 | 22\n",
        "> 69 | 96 | 70 | 103\n",
        "\n",
        "In a **linear regression** model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
        "\n",
        "```\n",
        "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "```\n",
        "\n",
        "It means that the yield of apples is a linear or planar function of the temperature, rainfall & humidity.\n",
        "\n",
        "\n",
        "\n",
        "**Our objective**: Find a suitable set of *weights* and *biases* using the training data, to make accurate predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c24b8195c0e9c6e8e13e169d264484f1f9b3b1ae",
        "id": "h0dmV2Fc-7oL"
      },
      "source": [
        "## Training Data\n",
        "The training data can be represented using 2 matrices (inputs and targets), each with one row per observation and one column for variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "dfda99005fc6daf3a49ae1cdd427ccac0aa446b1",
        "id": "MaIf33bV-7oN"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "bf56faf74f7e29c9ed7523308718a9ab1acc0667",
        "id": "1tnPriBD-7oa"
      },
      "source": [
        "# Target (apples)\n",
        "targets = np.array([[56], \n",
        "                    [81], \n",
        "                    [119], \n",
        "                    [22], \n",
        "                    [103]], dtype='float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "70d48f83ae4fce7aba7dd78fd58dddc77c598bfd",
        "id": "MyJm3YtE-7oo"
      },
      "source": [
        "Before we build a model, we need to convert inputs and targets to PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "931c1bad8788e607fa100d4338e1b1fe120e2339",
        "id": "KZyKnyCc-7oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114f80b3-fd98-47d2-9c7c-f848757992a5"
      },
      "source": [
        "# Convert inputs and targets to tensors\n",
        "input_tensor = torch.tensor(inputs,requires_grad=True)\n",
        "print(input_tensor)\n",
        "target_tensor= torch.tensor(targets,requires_grad=True)\n",
        "print(target_tensor)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]], requires_grad=True)\n",
            "tensor([[ 56.],\n",
            "        [ 81.],\n",
            "        [119.],\n",
            "        [ 22.],\n",
            "        [103.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "652647cd90bd0784ec4dc53472410f7358ee18c9",
        "id": "y0RLCJnb-7o4"
      },
      "source": [
        "## Linear Regression Model (from scratch)\n",
        "\n",
        "The *weights* and *biases* can also be represented as matrices, initialized with random values. The first row of `w` and the first element of `b` are use to predict the first target variable i.e. yield for apples, and similarly the second for oranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "6f788ae559355b3f01667be1554a5d2bdcade8db",
        "id": "OjToROni-7o5"
      },
      "source": [
        "# Weights and biases\n",
        "w = np.array([0.2, 0.5,0.3])\n",
        "b = 0.1\n",
        "\n",
        "y = np.matmul(w, input_tensor.detach().numpy().T) + b"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3579a065997cae41f7f504916b6bc07878ac768c",
        "id": "8qNNejI9-7pH"
      },
      "source": [
        "The *model* is simply a function that performs a matrix multiplication of the input `x` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
        "\n",
        "$$\n",
        "\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\left[ \\begin{array}{cc}\n",
        "73 & 67 & 43 \\\\\n",
        "91 & 88 & 64 \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "69 & 96 & 70\n",
        "\\end{array} \\right]\n",
        "%\n",
        "\\times\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "w_{11} & w_{21} \\\\\n",
        "w_{12} & w_{22} \\\\\n",
        "w_{13} & w_{23}\n",
        "\\end{array} \\right]\n",
        "%\n",
        "+\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "b_{1} & b_{2} \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\end{array} \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "b1119f5ae9688a5f31dba438c7f78ca382deb7e3",
        "id": "5G_d0Ka--7pJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49bb2a5b-7581-4c27-861a-527a2ca8e500"
      },
      "source": [
        "# Define the model\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(input_tensor.detach().numpy(), y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8e0a4644cb1c4ed68a3bcf67a8a156341ac7c853",
        "id": "nT94e2ZK-7pb"
      },
      "source": [
        "The matrix obtained by passing the input data to the model is a set of predictions for the target variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "b042a3cf8f16f4c4380cccbac9d0892719c24190",
        "id": "VUpnkKlO-7pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "764cbf9f-6f62-4a84-c76e-f589bba03872"
      },
      "source": [
        "# Generate predictions\n",
        "y_pred=lr.predict(input_tensor.detach().numpy())\n",
        "print(y_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 61.100006  81.5      101.899994  53.100002  82.9     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "5551ef933de7902c8b5a38ae3d8e4795cb244f38",
        "id": "KuIPDbJV-7po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ced323c-25c4-4c85-cb10-8dcab456b63a"
      },
      "source": [
        "# Compare with targets\n",
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(target_tensor.detach().numpy(), y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(target_tensor.detach().numpy(), y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(target_tensor.detach().numpy(), y_pred)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 14.780002\n",
            "Mean Squared Error: 337.9781\n",
            "Root Mean Squared Error: 18.38418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2c4a9cf2b3c9152f2f832176bce9a87381e2419c",
        "id": "Q-NuYiwI-7p4"
      },
      "source": [
        "Because we've started with random weights and biases, the model does not perform a good job of predicting the target varaibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "edaae7266f5d47c5e970e1438a812f10d8d35fb4",
        "id": "hiNOZ2g1-7p7"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "We can compare the predictions with the actual targets, using the following method: \n",
        "* Calculate the difference between the two matrices (`preds` and `targets`).\n",
        "* Square all elements of the difference matrix to remove negative values.\n",
        "* Calculate the average of the elements in the resulting matrix.\n",
        "\n",
        "The result is a single number, known as the **mean squared error** (MSE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "dbf5bca8cbf2a3831089b454c70469e3748e9682",
        "id": "_wY9fW06-7p9"
      },
      "source": [
        "\n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return np.sum(diff * diff) / diff.size"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "90da6779aad81608c40cdca77c3c04b68a815c11",
        "id": "V__m5zOU-7qH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c10a79-cffc-420a-97dd-e4bdd59c1c19"
      },
      "source": [
        "# Compute loss\n",
        "preds = model(input_tensor.detach().numpy(),w)\n",
        "cost_initial = mse(preds, target_tensor.detach().numpy())\n",
        "print(\"Cost before regression: \",cost_initial)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost before regression:  1482.8080000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3ab3acadf389f30430b55c26c7979dcffaa974a5",
        "id": "j-TOY_7g-7qS"
      },
      "source": [
        "The resulting number is called the **loss**, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c61acf9c3cff205d769fc52ed3b1b76f5ae66233",
        "id": "kbQQKg0_-7qU"
      },
      "source": [
        "## Compute Gradients\n",
        "\n",
        "With PyTorch, we can automatically compute the gradient or derivative of the `loss` w.r.t. to the weights and biases, because they have `requires_grad` set to `True`.\n",
        "\n",
        "More on autograd:  https://pytorch.org/docs/stable/autograd.html#module-torch.autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ef66710c6ef1944567c4dc033e1ca316f35490ab",
        "id": "jMUIxzeO-7qW"
      },
      "source": [
        "# Compute gradients\n",
        "def model(x,w):\n",
        "    return x @ w.T"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4USbQn_XMlm9"
      },
      "source": [
        "def gradient_descent(X, y, w, learning_rate, n_iters):\n",
        "    J_history = np.zeros((n_iters,1))\n",
        "    for i in range(n_iters):\n",
        "        h = model(X,w)\n",
        "        diff = h - y\n",
        "        delta = (learning_rate/y.size)*(X.T@diff)\n",
        "        new_w = w - delta.T\n",
        "        w=new_w\n",
        "        J_history[i] = mse(h, y)\n",
        "    return (J_history, w)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5201901695f3ea13d7fdd5d985da7e0761c541d0",
        "id": "JvUhV8nQ-7s9"
      },
      "source": [
        "## Train for multiple epochs\n",
        "\n",
        "To reduce the loss further, we repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "9f5f0ffeee666b30c5828636359f0be6addbef7c",
        "id": "rX0ZllBO-7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb91e6c-dde8-4dfa-87fd-95d1eb2d39b0"
      },
      "source": [
        "# Train for 100 epochs\n",
        "import matplotlib.pyplot as plt\n",
        "n_iters = 500\n",
        "learning_rate = 0.01\n",
        "\n",
        "initial_cost = mse(model(input_tensor.detach().numpy(),w),target_tensor.detach().numpy())\n",
        "\n",
        "print(\"Initial cost is: \", initial_cost, \"\\n\")\n",
        "\n",
        "(J_history, optimal_params) = gradient_descent(input_tensor.detach().numpy(), target_tensor.detach().numpy(), w, learning_rate, n_iters)\n",
        "\n",
        "print(\"Optimal parameters are: \\n\", optimal_params, \"\\n\")\n",
        "\n",
        "print(\"Final cost is: \", J_history[-1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial cost is:  1482.8080000000002 \n",
            "\n",
            "Optimal parameters are: \n",
            " [[nan nan nan]\n",
            " [nan nan nan]\n",
            " [nan nan nan]\n",
            " [nan nan nan]\n",
            " [nan nan nan]] \n",
            "\n",
            "Final cost is:  [nan]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in multiply\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in matmul\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in subtract\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "O6tY9XNFNHrV",
        "outputId": "595a3561-12cc-46cb-ecc1-40c3b3925ba2"
      },
      "source": [
        "plt.plot(range(len(J_history)), J_history, 'r')\n",
        "\n",
        "plt.title(\"Convergence Graph of Cost Function\")\n",
        "plt.xlabel(\"Number of Iterations\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU5jTa-dNL2w"
      },
      "source": [
        "# Calculate error\n",
        "preds = model(X,optimal_params)\n",
        "cost_final = mse(preds, Y)\n",
        "# Print predictions\n",
        "print(\"Prediction:\\n\",preds)\n",
        "# Comparing predicted with targets\n",
        "print(\"Targets:\\n\",Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG5MiKdlNPBW"
      },
      "source": [
        "print(\"Cost after linear regression: \",cost_final)\n",
        "print(\"Cost reduction percentage : {} %\".format(((cost_initial- cost_final)/cost_initial)*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}